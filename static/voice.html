<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>üöÄ AudioWorklet Voice AI</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body { background: #fff; color: #222; font-family: 'Segoe UI', sans-serif; margin: 0; min-height: 100vh; }
        .container { display: flex; flex-direction: column; align-items: center; justify-content: center; min-height: 100vh; padding: 20px; }
        .chat-window { width: 100%; max-width: 500px; background: #fff; border-radius: 24px; box-shadow: 0 4px 32px rgba(0, 0, 0, 0.08); overflow: hidden; display: flex; flex-direction: column; height: 600px; }
        .chat-header { background: #2563eb; color: #fff; text-align: center; padding: 15px; font-size: 1.5rem; font-weight: bold; }
        .chat-messages { padding: 20px; flex: 1; overflow-y: auto; background: #fff; display: flex; flex-direction: column; gap: 10px; }
        .message { padding: 12px 16px; border-radius: 12px; font-size: 1rem; line-height: 1.5; max-width: 80%; word-break: break-word; }
        .message.user { background: #e0e7ff; color: #222; align-self: flex-end; border: 1px solid #c7d2fe; }
        .message.assistant { background: #f3f4f6; color: #222; align-self: flex-start; border: 1px solid #e5e7eb; }
        .status-bar { background: #f8fafc; color: #64748b; text-align: center; padding: 8px; font-size: 0.9rem; border-top: 1px solid #e2e8f0; }
        .bottom-bar { background: #fff; padding: 15px; display: flex; align-items: center; justify-content: center; border-top: 1px solid #f1f5f9; }
        .input-bar { display: flex; align-items: center; width: 100%; gap: 10px; }
        .input-box { flex: 1; padding: 12px; border: 1px solid #e2e8f0; border-radius: 20px; background: #f8fafc; outline: none; }
        .mic-btn, .stop-btn { width: 50px; height: 50px; border-radius: 50%; border: none; color: #fff; display: flex; align-items: center; justify-content: center; cursor: pointer; font-size: 1.2rem; transition: 0.2s; }
        .mic-btn { background: #2563eb; }
        .mic-btn:hover { transform: scale(1.05); }
        .stop-btn { background: #ef4444; display: none; }
        .mic-btn.recording { background: #ef4444; animation: pulse 1.5s infinite; }
        .mic-btn.interrupt-ready { background: #f59e0b; }
        @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.6; } 100% { opacity: 1; } }
    </style>
</head>
<body>
    <div class="container">
        <div class="chat-window">
            <div class="chat-header">AI Voice (WAV/Worklet)</div>
            <div class="chat-messages" id="chat-messages"></div>
            <div class="status-bar" id="status">Ready to connect</div>
            <div class="bottom-bar">
                <div class="input-bar">
                    <input id="textInput" class="input-box" type="text" placeholder="Start speaking..." readonly />
                    <button id="micBtn" class="mic-btn">üéôÔ∏è</button>
                    <button id="stopBtn" class="stop-btn">‚èπÔ∏è</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // ==========================================
        // üß† AUDIO WORKLET CODE (Runs on separate thread)
        // ==========================================
        const workletCode = `
            class RecorderProcessor extends AudioWorkletProcessor {
                constructor() {
                    super();
                    this.bufferSize = 4096;
                }
                process(inputs, outputs, parameters) {
                    const input = inputs[0];
                    if (input.length > 0) {
                        const channelData = input[0];
                        
                        // Calculate Volume (RMS) directly in thread
                        let sum = 0;
                        for (let i = 0; i < channelData.length; i++) {
                            sum += channelData[i] * channelData[i];
                        }
                        const rms = Math.sqrt(sum / channelData.length);
                        
                        // Send Raw PCM + Volume to Main Thread
                        this.port.postMessage({
                            audio: channelData,
                            volume: rms * 100 
                        });
                    }
                    return true;
                }
            }
            registerProcessor('recorder-worklet', RecorderProcessor);
        `;

        // ==========================================
        // üü¢ MAIN THREAD CODE
        // ==========================================
        const statusDiv = document.getElementById('status');
        const chatMessages = document.getElementById('chat-messages');
        const micBtn = document.getElementById('micBtn');
        const stopBtn = document.getElementById('stopBtn');

        // --- Variables ---
        let ws = null;
        let sessionId = null;
        let isProcessingQuery = false;
        let isBotSpeaking = false;
        let isManualStop = false;
        
        // --- Audio Recording ---
        let audioContext = null;
        let mediaStream = null;
        let workletNode = null;
        let sourceNode = null;
        let pcmData = []; 
        let isRecording = false;

        // --- Playback ---
        let playbackCtx = null;
        let nextStartTime = 0;
        const BUFFER_AHEAD = 0.5;

        // --- Detection Logic ---
        let silenceStart = Date.now();
        let recordingStart = Date.now();
        let hasSpoken = false;

        function addMessage(text, sender) {
            const div = document.createElement('div');
            div.className = `message ${sender}`;
            div.textContent = text;
            chatMessages.appendChild(div);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function handleConnectionLost(reason) {
            console.log("üõë Reset:", reason);
            isManualStop = true; 
            isBotSpeaking = false;
            isProcessingQuery = false;
            
            stopAudioPlayback();
            stopWavRecording(); 
            
            if (ws) { ws.close(); ws = null; }

            statusDiv.textContent = "Disconnected. Click mic.";
            statusDiv.style.color = "red";
            stopBtn.style.display = 'none';
            micBtn.style.display = 'flex';
            micBtn.classList.remove('recording', 'interrupt-ready');
            micBtn.disabled = false;
        }

        // --- PLAYBACK ---
        function initPlayback() {
            if (!playbackCtx) playbackCtx = new (window.AudioContext || window.webkitAudioContext)();
            if (playbackCtx.state === 'suspended') playbackCtx.resume();
        }

        async function playAudioChunk(base64Data) {
            if(isManualStop) return;
            initPlayback();
            const binaryString = atob(base64Data);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
            try {
                const buffer = await playbackCtx.decodeAudioData(bytes.buffer);
                scheduleBuffer(buffer);
            } catch (e) { console.error(e); }
        }

        function scheduleBuffer(buffer) {
            if(isManualStop) return;
            const src = playbackCtx.createBufferSource();
            src.buffer = buffer;
            src.connect(playbackCtx.destination);
            const now = playbackCtx.currentTime;
            if (nextStartTime < now) nextStartTime = now + BUFFER_AHEAD;
            src.start(nextStartTime);
            nextStartTime += buffer.duration;
            isBotSpeaking = true;
            micBtn.classList.add("interrupt-ready");
            if(!isManualStop) statusDiv.textContent = "ü§ñ Speaking...";
        }

        function stopAudioPlayback() {
            if (playbackCtx) { playbackCtx.close().then(() => { playbackCtx = null; nextStartTime = 0; }); }
            isBotSpeaking = false;
            micBtn.classList.remove("interrupt-ready");
        }

        // ==========================================
        // üé§ SETUP AUDIO WORKLET (Replaces ScriptProcessor)
        // ==========================================
        async function setupAudioWorklet() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 }); // Force 16kHz
            }
            
            // Resume if suspended
            if (audioContext.state === 'suspended') await audioContext.resume();

            // Load Module only once
            try {
                // Check if worklet is already registered (not possible directly, so we try-catch addModule)
                // Using Blob to load string as file
                const blob = new Blob([workletCode], { type: "application/javascript" });
                const url = URL.createObjectURL(blob);
                await audioContext.audioWorklet.addModule(url);
                console.log("‚úÖ Audio Worklet Loaded");
            } catch (e) {
                console.log("Worklet might already be loaded or error:", e);
            }
        }

        async function startWavRecording() {
            if (isManualStop || !ws || ws.readyState !== WebSocket.OPEN) return;
            if (isRecording) return; // Already running

            try {
                await setupAudioWorklet();

                if (!mediaStream) {
                    mediaStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true } 
                    });
                }

                sourceNode = audioContext.createMediaStreamSource(mediaStream);
                workletNode = new AudioWorkletNode(audioContext, 'recorder-worklet');

                sourceNode.connect(workletNode);
                workletNode.connect(audioContext.destination); // Connect to dest to keep it alive (often needed in Chrome)

                isRecording = true;
                pcmData = [];
                hasSpoken = false;
                recordingStart = Date.now();
                silenceStart = Date.now();

                // --- PROCESS DATA FROM WORKLET ---
                workletNode.port.onmessage = (event) => {
                    if (!isRecording) return;

                    const { audio, volume } = event.data;

                    // --- LOGIC: INTERRUPTION ---
                    if (isBotSpeaking) {
                        if (volume > 5) { // Interruption Threshold
                            console.log("üî• Interruption!");
                            stopAudioPlayback();
                            pcmData = []; 
                            hasSpoken = true;
                            recordingStart = Date.now();
                            pcmData.push(audio); // Capture interrupt chunk
                            statusDiv.textContent = "üéôÔ∏è Interrupted! Listening...";
                            statusDiv.style.color = "#ef5350";
                        }
                        return;
                    }

                    // --- LOGIC: RECORDING ---
                    if (!isProcessingQuery) {
                        pcmData.push(audio);
                    }

                    // --- LOGIC: SILENCE ---
                    if (volume > 2) { // Speech Threshold
                        hasSpoken = true;
                        silenceStart = Date.now();
                        statusDiv.textContent = "üéôÔ∏è Listening...";
                        statusDiv.style.color = "#ef5350";
                    } else if (hasSpoken) {
                        // 2s Silence Detection
                        if (Date.now() - silenceStart > 2000) { 
                            if (Date.now() - recordingStart > 1000) { 
                                console.log("‚úÖ Silence. Sending WAV...");
                                sendWavData();
                            }
                        }
                    }
                };

                micBtn.style.display = 'none';
                stopBtn.style.display = 'inline-flex';
                statusDiv.textContent = "üéôÔ∏è Listening...";
                statusDiv.style.color = "#666";

            } catch (e) {
                console.error(e);
                handleConnectionLost("Mic Error");
            }
        }

        function stopWavRecording() {
            isRecording = false;
            if (workletNode) { workletNode.disconnect(); workletNode = null; }
            if (sourceNode) { sourceNode.disconnect(); sourceNode = null; }
            if (audioContext) { audioContext.close(); audioContext = null; }
            if (mediaStream) { mediaStream.getTracks().forEach(t => t.stop()); mediaStream = null; }
            pcmData = [];
        }

        function sendWavData() {
            isRecording = false; 
            
            let length = 0;
            pcmData.forEach(d => length += d.length);
            
            if (length === 0) { isRecording = true; return; }

            let merged = new Float32Array(length);
            let offset = 0;
            pcmData.forEach(d => { merged.set(d, offset); offset += d.length; });

            const wavBlob = encodeWAV(merged);
            
            isProcessingQuery = true;
            statusDiv.textContent = "ü§ñ Thinking...";
            statusDiv.style.color = "#2563eb";

            const reader = new FileReader();
            reader.readAsDataURL(wavBlob);
            reader.onloadend = () => {
                const base64 = reader.result.split(',')[1];
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ audio: base64, session_id: sessionId }));
                }
                pcmData = [];
                hasSpoken = false;
                isRecording = true; 
            };
        }

        // --- WAV ENCODER ---
        function encodeWAV(samples) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true); 
            view.setUint16(22, 1, true); 
            view.setUint32(24, 16000, true); 
            view.setUint32(28, 16000 * 2, true); 
            view.setUint16(32, 2, true); 
            view.setUint16(34, 16, true); 
            writeString(view, 36, 'data');
            view.setUint32(40, samples.length * 2, true);
            floatTo16BitPCM(view, 44, samples);
            return new Blob([view], { type: 'audio/wav' });
        }

        function floatTo16BitPCM(output, offset, input) {
            for (let i = 0; i < input.length; i++, offset += 2) {
                let s = Math.max(-1, Math.min(1, input[i]));
                s = s < 0 ? s * 0x8000 : s * 0x7FFF;
                output.setInt16(offset, s, true);
            }
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // --- WEBSOCKET ---
        function initWebSocket() {
            micBtn.disabled = true;
            statusDiv.textContent = "üîÑ Connecting...";
            
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            ws = new WebSocket(`${protocol}//${window.location.host}/ws/voice`);

            ws.onopen = () => statusDiv.textContent = "‚è≥ Authenticating...";

            ws.onmessage = (event) => {
                if(isManualStop) return;
                const data = JSON.parse(event.data);

                if (data.session_id) {
                    sessionId = data.session_id;
                    micBtn.disabled = false;
                    startWavRecording();
                    return;
                }

                if (isProcessingQuery) isProcessingQuery = false;

                if (data.type === 'text_start') {
                    addMessage(data.bot_text, 'assistant');
                    if(data.user_text) addMessage(data.user_text, 'user');
                    statusDiv.textContent = "ü§ñ Speaking...";
                } else if (data.type === 'audio_chunk') {
                    playAudioChunk(data.audio);
                } else if (data.type === 'error') {
                    statusDiv.textContent = "Error: " + data.message;
                }
            };

            ws.onerror = () => handleConnectionLost("Socket Error");
            ws.onclose = () => handleConnectionLost("Socket Closed");
        }

        // --- BUTTONS ---
        micBtn.onclick = () => {
            isManualStop = false;
            if (isBotSpeaking) {
                stopAudioPlayback();
                pcmData = [];
                return;
            }
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                initWebSocket();
            } else {
                startWavRecording();
            }
        };

        stopBtn.onclick = () => {
            if (ws) ws.send(JSON.stringify({ stop: true }));
            handleConnectionLost("Manual Stop");
        };
    </script>
</body>
</html>