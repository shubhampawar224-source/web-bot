<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>üé§ WAV Voice AI</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            background: #fff;
            color: #222;
            font-family: 'Segoe UI', sans-serif;
            margin: 0;
            min-height: 100vh;
        }

        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            padding: 20px;
        }

        .chat-window {
            width: 100%;
            max-width: 500px;
            background: #fff;
            border-radius: 24px;
            box-shadow: 0 4px 32px rgba(0, 0, 0, 0.08);
            overflow: hidden;
            display: flex;
            flex-direction: column;
            height: 600px;
        }

        .chat-header {
            background: #2563eb;
            color: #fff;
            text-align: center;
            padding: 15px;
            font-size: 1.5rem;
            font-weight: bold;
        }

        .chat-messages {
            padding: 20px;
            flex: 1;
            overflow-y: auto;
            background: #fff;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .message {
            padding: 12px 16px;
            border-radius: 12px;
            font-size: 1rem;
            line-height: 1.5;
            max-width: 80%;
            word-break: break-word;
        }

        .message.user {
            background: #e0e7ff;
            color: #222;
            align-self: flex-end;
            border: 1px solid #c7d2fe;
        }

        .message.assistant {
            background: #f3f4f6;
            color: #222;
            align-self: flex-start;
            border: 1px solid #e5e7eb;
        }

        .status-bar {
            background: #f8fafc;
            color: #64748b;
            text-align: center;
            padding: 8px;
            font-size: 0.9rem;
            border-top: 1px solid #e2e8f0;
        }

        .bottom-bar {
            background: #fff;
            padding: 15px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-top: 1px solid #f1f5f9;
        }

        .input-bar {
            display: flex;
            align-items: center;
            width: 100%;
            gap: 10px;
        }

        .input-box {
            flex: 1;
            padding: 12px;
            border: 1px solid #e2e8f0;
            border-radius: 20px;
            background: #f8fafc;
            outline: none;
        }

        .mic-btn,
        .stop-btn {
            width: 50px;
            height: 50px;
            border-radius: 50%;
            border: none;
            color: #fff;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            font-size: 1.2rem;
            transition: 0.2s;
        }

        .mic-btn {
            background: #2563eb;
        }

        .mic-btn:hover {
            transform: scale(1.05);
        }

        .stop-btn {
            background: #ef4444;
            display: none;
        }

        .mic-btn.recording {
            background: #ef4444;
            animation: pulse 1.5s infinite;
        }

        .mic-btn.interrupt-ready {
            background: #f59e0b;
        }

        @keyframes pulse {
            0% {
                opacity: 1;
            }

            50% {
                opacity: 0.6;
            }

            100% {
                opacity: 1;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="chat-window">
            <div class="chat-header">Voice AI (WAV)</div>
            <div class="chat-messages" id="chat-messages"></div>
            <div class="status-bar" id="status">Ready to connect</div>
            <div class="bottom-bar">
                <div class="input-bar">
                    <input id="textInput" class="input-box" type="text" placeholder="Start speaking..." readonly />
                    <button id="micBtn" class="mic-btn">üéôÔ∏è</button>
                    <button id="stopBtn" class="stop-btn">‚èπÔ∏è</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        const statusDiv = document.getElementById('status');
        const chatMessages = document.getElementById('chat-messages');
        const micBtn = document.getElementById('micBtn');
        const stopBtn = document.getElementById('stopBtn');

        // --- Core Variables ---
        let ws = null;
        let sessionId = null;

        // --- State Flags ---
        let isProcessingQuery = false;
        let isBotSpeaking = false;
        let isManualStop = false;

        // --- Audio Recording (WAV) ---
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let input = null;
        let isRecording = false;
        let pcmData = []; // Raw audio data buffer

        // --- Playback ---
        let playbackCtx = null;
        let nextStartTime = 0;
        const BUFFER_AHEAD = 0.5;

        // --- Detection ---
        let silenceStart = Date.now();
        let recordingStart = Date.now();
        let hasSpoken = false;
        let volumeInterval = null;

        function addMessage(text, sender) {
            const div = document.createElement('div');
            div.className = `message ${sender}`;
            div.textContent = text;
            chatMessages.appendChild(div);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        function handleConnectionLost(reason) {
            console.log("üõë Reset:", reason);
            isManualStop = true;
            isBotSpeaking = false;
            isProcessingQuery = false;

            stopAudioPlayback();
            stopWavRecording(); // Kill mic

            if (ws) { ws.close(); ws = null; }

            statusDiv.textContent = "Disconnected. Click mic.";
            statusDiv.style.color = "red";
            stopBtn.style.display = 'none';
            micBtn.style.display = 'flex';
            micBtn.classList.remove('recording', 'interrupt-ready');
            micBtn.disabled = false;
        }

        // ==========================================
        // üîä AUDIO PLAYBACK (Gapless)
        // ==========================================
        function initPlayback() {
            if (!playbackCtx) playbackCtx = new (window.AudioContext || window.webkitAudioContext)();
            if (playbackCtx.state === 'suspended') playbackCtx.resume();
        }

        async function playAudioChunk(base64Data) {
            if (isManualStop) return;
            initPlayback();
            const binaryString = atob(base64Data);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
            try {
                const buffer = await playbackCtx.decodeAudioData(bytes.buffer);
                scheduleBuffer(buffer);
            } catch (e) { console.error(e); }
        }

        function scheduleBuffer(buffer) {
            if (isManualStop) return;
            const src = playbackCtx.createBufferSource();
            src.buffer = buffer;
            src.connect(playbackCtx.destination);

            const now = playbackCtx.currentTime;
            if (nextStartTime < now) nextStartTime = now + BUFFER_AHEAD;

            src.start(nextStartTime);
            nextStartTime += buffer.duration;

            isBotSpeaking = true;
            micBtn.classList.add("interrupt-ready");
            if (!isManualStop) statusDiv.textContent = "ü§ñ Speaking...";
        }

        function stopAudioPlayback() {
            if (playbackCtx) { playbackCtx.close().then(() => { playbackCtx = null; nextStartTime = 0; }); }
            isBotSpeaking = false;
            micBtn.classList.remove("interrupt-ready");
        }

        // ==========================================
        // üé§ MANUAL WAV RECORDING (The Fix)
        // ==========================================
        async function startWavRecording() {
            if (isManualStop || !ws || ws.readyState !== WebSocket.OPEN) return;

            // If already recording, just reset buffers (Don't restart stream)
            if (isRecording) return;

            try {
                if (!mediaStream) {
                    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true } });
                }

                if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 }); // Force 16kHz for small WAV

                input = audioContext.createMediaStreamSource(mediaStream);
                // Processor buffer size 4096 = approx 250ms latency
                processor = audioContext.createScriptProcessor(4096, 1, 1);

                input.connect(processor);
                processor.connect(audioContext.destination);

                isRecording = true;
                pcmData = [];
                hasSpoken = false;
                recordingStart = Date.now();
                silenceStart = Date.now();

                // AUDIO PROCESS LOOP
                processor.onaudioprocess = (e) => {
                    if (!isRecording) return;

                    const inputData = e.inputBuffer.getChannelData(0);

                    // 1. Volume Detection (Manual calculation)
                    let sum = 0;
                    for (let i = 0; i < inputData.length; i++) sum += inputData[i] * inputData[i];
                    const rms = Math.sqrt(sum / inputData.length);
                    const volume = rms * 100; // rough scale

                    // --- LOGIC: INTERRUPTION ---
                    if (isBotSpeaking) {
                        if (volume > 5) { // Interruption Threshold
                            console.log("üî• Interruption!");
                            stopAudioPlayback();
                            pcmData = []; // Clear buffer (ignore bot sound)
                            // Keep recording User's voice immediately
                            hasSpoken = true;
                            recordingStart = Date.now();

                            // Capture this chunk!
                            const bufferCopy = new Float32Array(inputData);
                            pcmData.push(bufferCopy);

                            statusDiv.textContent = "üéôÔ∏è Interrupted! Listening...";
                            statusDiv.style.color = "#ef5350";
                        }
                        return; // Don't collect data if bot is speaking and user is silent
                    }

                    // --- LOGIC: RECORDING ---
                    // Only collect data if not waiting for processing
                    if (!isProcessingQuery) {
                        const bufferCopy = new Float32Array(inputData);
                        pcmData.push(bufferCopy);
                    }

                    // --- LOGIC: SILENCE ---
                    if (volume > 2) { // Speech Threshold
                        hasSpoken = true;
                        silenceStart = Date.now();
                        statusDiv.textContent = "üéôÔ∏è Listening...";
                        statusDiv.style.color = "#ef5350";
                    } else if (hasSpoken) {
                        // Silence Logic
                        if (Date.now() - silenceStart > 2000) { // 2s Silence
                            if (Date.now() - recordingStart > 1000) { // Min 1s recording
                                console.log("‚úÖ Silence. Sending WAV...");
                                sendWavData();
                            }
                        }
                    }
                };

                micBtn.style.display = 'none';
                stopBtn.style.display = 'inline-flex';
                statusDiv.textContent = "üéôÔ∏è Listening...";
                statusDiv.style.color = "#666";

            } catch (e) {
                console.error(e);
                handleConnectionLost("Mic Error");
            }
        }

        function stopWavRecording() {
            isRecording = false;
            if (processor) { processor.disconnect(); processor = null; }
            if (input) { input.disconnect(); input = null; }
            if (audioContext) { audioContext.close(); audioContext = null; }
            if (mediaStream) { mediaStream.getTracks().forEach(t => t.stop()); mediaStream = null; }
            pcmData = [];
        }

        function sendWavData() {
            isRecording = false; // Pause recording

            // 1. Flatten Data
            let length = 0;
            pcmData.forEach(d => length += d.length);

            if (length === 0) {
                // Restart if empty
                isRecording = true;
                return;
            }

            let merged = new Float32Array(length);
            let offset = 0;
            pcmData.forEach(d => { merged.set(d, offset); offset += d.length; });

            // 2. Encode WAV (16-bit PCM)
            const wavBlob = encodeWAV(merged);

            // 3. Send
            isProcessingQuery = true;
            statusDiv.textContent = "ü§ñ Thinking...";
            statusDiv.style.color = "#2563eb";

            const reader = new FileReader();
            reader.readAsDataURL(wavBlob);
            reader.onloadend = () => {
                const base64 = reader.result.split(',')[1];
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ audio: base64, session_id: sessionId }));
                }
                // Don't stop mic fully, just reset buffers for next turn
                pcmData = [];
                hasSpoken = false;
                // Note: isRecording will be set to true when response finishes or we force it.
                // Actually, we should keep it true to catch interruption, but we paused logic.
                // Let's keep listener alive but ignore data until response or interrupt.
                // Handled by `if (!isProcessingQuery)` check above.
                isRecording = true;
            };
        }

        // --- WAV ENCODER HELPER ---
        function encodeWAV(samples) {
            const buffer = new ArrayBuffer(44 + samples.length * 2);
            const view = new DataView(buffer);

            // RIFF chunk descriptor
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples.length * 2, true);
            writeString(view, 8, 'WAVE');
            // fmt sub-chunk
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true); // PCM
            view.setUint16(22, 1, true); // Mono
            view.setUint32(24, 16000, true); // Sample Rate
            view.setUint32(28, 16000 * 2, true); // Byte Rate
            view.setUint16(32, 2, true); // Block Align
            view.setUint16(34, 16, true); // Bits per sample
            // data sub-chunk
            writeString(view, 36, 'data');
            view.setUint32(40, samples.length * 2, true);

            // Write PCM samples
            floatTo16BitPCM(view, 44, samples);

            return new Blob([view], { type: 'audio/wav' });
        }

        function floatTo16BitPCM(output, offset, input) {
            for (let i = 0; i < input.length; i++, offset += 2) {
                let s = Math.max(-1, Math.min(1, input[i]));
                s = s < 0 ? s * 0x8000 : s * 0x7FFF;
                output.setInt16(offset, s, true);
            }
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

        // --- WEBSOCKET ---
        function initWebSocket() {
            micBtn.disabled = true;
            statusDiv.textContent = "üîÑ Connecting...";

            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            ws = new WebSocket(`${protocol}//${window.location.host}/ws/voice`);

            ws.onopen = () => statusDiv.textContent = "‚è≥ Authenticating...";

            ws.onmessage = (event) => {
                if (isManualStop) return;
                const data = JSON.parse(event.data);

                if (data.session_id) {
                    sessionId = data.session_id;
                    micBtn.disabled = false;
                    startWavRecording(); // Auto Start
                    return;
                }

                if (isProcessingQuery) isProcessingQuery = false;

                if (data.type === 'text_start') {
                    addMessage(data.bot_text, 'assistant');
                    if (data.user_text) addMessage(data.user_text, 'user');
                    statusDiv.textContent = "ü§ñ Speaking...";
                } else if (data.type === 'audio_chunk') {
                    playAudioChunk(data.audio);
                } else if (data.type === 'error') {
                    statusDiv.textContent = "Error: " + data.message;
                }
            };

            ws.onerror = () => handleConnectionLost("Socket Error");
            ws.onclose = () => handleConnectionLost("Socket Closed");
        }

        // --- BUTTONS ---
        micBtn.onclick = () => {
            isManualStop = false;
            if (isBotSpeaking) {
                // Force interruption manually if needed
                stopAudioPlayback();
                pcmData = [];
                return;
            }
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                initWebSocket();
            } else {
                startWavRecording();
            }
        };

        stopBtn.onclick = () => {
            if (ws) ws.send(JSON.stringify({ stop: true }));
            handleConnectionLost("Manual Stop");
        };
    </script>
</body>

</html>