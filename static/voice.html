<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>üöÄ Robust Voice AI</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
            background: #f6f7fa;
            margin: 0;
            min-height: 100vh;
        }

        .container {
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
            padding: 20px 10px;
        }

        .chat-window {
            width: 100%;
            max-width: 480px;
            height: 500px;
            background: #fff;
            border-radius: 22px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            display: flex;
            flex-direction: column;
            overflow: hidden;
            border: 1.5px solid #e0e6ed;
        }

        .chat-header {
            background: #4a90e2;
            color: #fff;
            padding: 20px 0;
            text-align: center;
            font-size: 1.4rem;
            font-weight: bold;
        }

        .chat-messages {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            display: flex;
            flex-direction: column;
            gap: 15px;
            background: #fcfdff;
        }

        .message {
            padding: 12px 18px;
            border-radius: 14px;
            max-width: 85%;
            line-height: 1.5;
            font-size: 15px;
            word-break: break-word;
        }

        .message.user {
            background: #e3f2fd;
            color: #1565c0;
            align-self: flex-end;
            border-bottom-right-radius: 2px;
        }

        .message.assistant {
            background: #f5f5f5;
            color: #333;
            align-self: flex-start;
            border-bottom-left-radius: 2px;
            border: 1px solid #eee;
        }

        .status-bar {
            background: #fff8e1;
            color: #f57f17;
            font-size: 13px;
            text-align: center;
            padding: 4px 8px;
            border-top: 1px solid #ffe082;
        }

        .bottom-bar {
            background: #fff;
            padding: 15px;
            border-top: 1px solid #eee;
        }

        .input-bar {
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .input-box {
            flex: 1;
            padding: 12px;
            border: 1px solid #ddd;
            border-radius: 25px;
            outline: none;
            background: #f9f9f9;
        }

        .mic-btn,
        .stop-btn {
            width: 48px;
            height: 48px;
            border-radius: 50%;
            border: none;
            font-size: 20px;
            cursor: pointer;
            color: white;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: 0.2s;
        }

        .mic-btn {
            background: #4a90e2;
        }

        .mic-btn:hover {
            background: #357abd;
            transform: scale(1.05);
        }

        .mic-btn.recording {
            background: #ef5350;
            animation: pulse 1.5s infinite;
        }

        .mic-btn.interrupt-ready {
            background: #ffa726;
        }

        .stop-btn {
            background: #ef5350;
            display: none;
        }

        .stop-btn:hover {
            background: #d32f2f;
        }

        @keyframes pulse {
            0% {
                opacity: 1;
            }

            50% {
                opacity: 0.5;
            }

            100% {
                opacity: 1;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="chat-window">
            <div class="chat-header">AI voice assistant</div>
            <div class="chat-messages" id="chat-messages"></div>
            <div class="status-bar" id="status">Ready to connect</div>
            <div class="bottom-bar">
                <div class="input-bar">
                    <input id="textInput" class="input-box" type="text" placeholder="Start speaking..." readonly />
                    <button id="micBtn" class="mic-btn">üéôÔ∏è</button>
                    <button id="stopBtn" class="stop-btn">‚èπÔ∏è</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        // --- UI Elements ---
        const statusDiv = document.getElementById('status');
        const chatMessages = document.getElementById('chat-messages');
        const micBtn = document.getElementById('micBtn');
        const stopBtn = document.getElementById('stopBtn');

        // --- Core State ---
        let ws = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let sessionId = null;

        // --- Flags ---
        let isProcessingQuery = false;
        let isBotSpeaking = false;
        let isWaitingForResponse = false;
        let isManualStop = false;
        let isRecording = false;

        // --- Audio Context & Streams ---
        let currentStream = null;
        let recordingContext = null;
        let audioCtx = null;
        let nextStartTime = 0;
        const BUFFER_AHEAD_TIME = 0.5;

        // --- Detection Vars ---
        let silenceInterval = null;
        let voiceInterruptionStream = null;
        let voiceInterruptionContext = null;
        let voiceInterruptionAnalyser = null;
        let voiceInterruptionInterval = null;

        function addMessage(text, sender) {
            const div = document.createElement('div');
            div.className = `message ${sender}`;
            div.textContent = text;
            chatMessages.appendChild(div);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }

        // ==========================================
        // üî• THE FIX: CENTRALIZED DISCONNECT LOGIC
        // ==========================================
        function handleConnectionLost(reason) {
            console.log("üõë Connection Reset Triggered:", reason);

            // 1. Flags Reset (Sabse Pehle)
            isManualStop = true;
            isRecording = false;
            isBotSpeaking = false;
            isProcessingQuery = false;
            isWaitingForResponse = false;

            // 2. Kill Audio & Mic
            stopAudioPlayback();
            cleanupRecordingSession(true);

            // 3. Close Socket if open
            if (ws) {
                ws.onclose = null; // Prevent loop
                ws.onerror = null;
                if (ws.readyState === WebSocket.OPEN || ws.readyState === WebSocket.CONNECTING) {
                    ws.close();
                }
                ws = null;
            }

            // 4. Force UI Reset (Ye "Speaking..." ko hata dega)
            statusDiv.textContent = "Disconnected. Click mic to connect.";
            statusDiv.style.color = "red"; // Red color to indicate stopped

            stopBtn.style.display = 'none';
            micBtn.style.display = 'inline-flex';
            micBtn.classList.remove('recording', 'interrupt-ready');
            micBtn.disabled = false;
        }

        // --- AUDIO PLAYBACK ---
        function initAudioContext() {
            if (!audioCtx) audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            if (audioCtx.state === 'suspended') audioCtx.resume();
        }

        async function playAudioChunk(base64Data) {
            if (isManualStop) return; // Agar stop daba diya to audio mat chalao

            initAudioContext();
            const binaryString = atob(base64Data);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);

            try {
                const buffer = await audioCtx.decodeAudioData(bytes.buffer);
                scheduleBuffer(buffer);
            } catch (e) { console.error("Decode error", e); }
        }

        function scheduleBuffer(buffer) {
            if (isManualStop) return;

            const source = audioCtx.createBufferSource();
            source.buffer = buffer;
            source.connect(audioCtx.destination);

            const now = audioCtx.currentTime;
            if (nextStartTime < now) nextStartTime = now + BUFFER_AHEAD_TIME;

            source.start(nextStartTime);
            nextStartTime += buffer.duration;

            isBotSpeaking = true;
            micBtn.classList.add("interrupt-ready");

            // Speaking status sirf tab dikhana jab actually connect ho
            if (!isManualStop) statusDiv.textContent = "ü§ñ Speaking...";
        }

        function stopAudioPlayback() {
            if (audioCtx) {
                audioCtx.close().then(() => { audioCtx = null; nextStartTime = 0; });
            }
            isBotSpeaking = false;
        }

        function speakText(text) {
            window.speechSynthesis.cancel();
            const u = new SpeechSynthesisUtterance(text);
            window.speechSynthesis.speak(u);
        }

        // --- INTERRUPTION LOGIC ---
        async function startInterruptionDetection() {
            if (voiceInterruptionStream) return;
            try {
                voiceInterruptionStream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } });
                voiceInterruptionContext = new AudioContext();
                const source = voiceInterruptionContext.createMediaStreamSource(voiceInterruptionStream);
                voiceInterruptionAnalyser = voiceInterruptionContext.createAnalyser();
                voiceInterruptionAnalyser.fftSize = 2048;
                source.connect(voiceInterruptionAnalyser);

                const dataArray = new Float32Array(voiceInterruptionAnalyser.frequencyBinCount);
                let consecutive = 0;

                voiceInterruptionInterval = setInterval(() => {
                    if (!isBotSpeaking || isManualStop) return;
                    voiceInterruptionAnalyser.getFloatTimeDomainData(dataArray);
                    const rms = Math.sqrt(dataArray.reduce((s, v) => s + v * v, 0) / dataArray.length);
                    const db = 20 * Math.log10(rms + 1e-8);

                    if (db > -30) {
                        consecutive++;
                        if (consecutive >= 3) handleInterruption();
                    } else {
                        consecutive = Math.max(0, consecutive - 1);
                    }
                }, 200);
            } catch (e) { console.error(e); }
        }

        function stopInterruptionDetection() {
            if (voiceInterruptionInterval) clearInterval(voiceInterruptionInterval);
            if (voiceInterruptionStream) voiceInterruptionStream.getTracks().forEach(t => t.stop());
            if (voiceInterruptionContext) voiceInterruptionContext.close();
            voiceInterruptionStream = null;
        }

        function handleInterruption() {
            console.log("Interruption triggered");
            isBotSpeaking = false;
            stopAudioPlayback();
            stopInterruptionDetection();
            window.speechSynthesis.cancel();
            micBtn.classList.remove("interrupt-ready");

            cleanupRecordingSession(false);
            if (!isManualStop && ws && ws.readyState === WebSocket.OPEN) {
                statusDiv.textContent = "Interrupted! Listening...";
                setTimeout(startRecording, 500);
            }
        }

        function cleanupRecordingSession(fullStop = false) {
            stopInterruptionDetection();
            if (silenceInterval) clearInterval(silenceInterval);
            if (recordingContext) recordingContext.close();

            if (mediaRecorder && mediaRecorder.state !== "inactive") {
                if (fullStop) mediaRecorder.onstop = null;
                mediaRecorder.stop();
            }
            if (currentStream) currentStream.getTracks().forEach(t => t.stop());
            recordingContext = null;
            audioChunks = [];
        }

        // --- RECORDING ---
        async function startRecording() {
            if (isManualStop || !ws || ws.readyState !== WebSocket.OPEN) return;

            cleanupRecordingSession(false);
            if (isBotSpeaking) handleInterruption();

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } });
                currentStream = stream;
                recordingContext = new AudioContext();
                const source = recordingContext.createMediaStreamSource(stream);
                const analyser = recordingContext.createAnalyser();
                analyser.fftSize = 4096;
                source.connect(analyser);

                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                let hasSound = false;
                let silenceCount = 0;
                isRecording = true;
                const dataArray = new Float32Array(analyser.frequencyBinCount);

                silenceInterval = setInterval(() => {
                    if (!isRecording) return;
                    analyser.getFloatTimeDomainData(dataArray);
                    const rms = Math.sqrt(dataArray.reduce((s, v) => s + v * v, 0) / dataArray.length);
                    const db = 20 * Math.log10(rms + 1e-8);

                    if (db > -45) {
                        hasSound = true;
                        silenceCount = 0;
                        statusDiv.textContent = "üéôÔ∏è Listening...";
                        statusDiv.style.color = "#666";
                    } else if (hasSound) {
                        silenceCount++;
                        if (silenceCount > 10) {
                            isRecording = false;
                            mediaRecorder.stop();
                        }
                    }
                }, 200);

                setTimeout(() => { if (isRecording) mediaRecorder.stop(); }, 15000);

                mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
                mediaRecorder.onstop = () => {
                    if (isManualStop) return;
                    if (!hasSound) {
                        cleanupRecordingSession();
                        setTimeout(startRecording, 1000);
                        return;
                    }

                    isProcessingQuery = true;
                    statusDiv.textContent = "ü§ñ Thinking...";
                    const blob = new Blob(audioChunks, { type: 'audio/wav' });
                    const reader = new FileReader();
                    reader.readAsDataURL(blob);
                    reader.onloadend = () => {
                        const base64 = reader.result.split(',')[1];
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            ws.send(JSON.stringify({ audio: base64, session_id: sessionId }));
                        }
                    };
                };

                mediaRecorder.start();
                micBtn.style.display = 'none';
                stopBtn.style.display = 'inline-flex';
                statusDiv.textContent = "üéôÔ∏è Listening...";
                statusDiv.style.color = "#666";

            } catch (e) {
                console.error(e);
                handleConnectionLost("Mic Error");
            }
        }

        // --- WEBSOCKET SETUP ---
        function initWebSocket() {
            micBtn.disabled = true;
            statusDiv.textContent = "üîÑ Connecting...";
            statusDiv.style.color = "#666";

            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            ws = new WebSocket(`${protocol}//${window.location.host}/ws/voice`);

            ws.onopen = () => statusDiv.textContent = "‚è≥ Authenticating...";

            ws.onmessage = (event) => {
                if (isManualStop) return; // Ignore messages if stopped

                const data = JSON.parse(event.data);

                if (data.session_id) {
                    sessionId = data.session_id;
                    statusDiv.textContent = "üéôÔ∏è Ready!";
                    micBtn.disabled = false;
                    startRecording();
                    return;
                }

                if (isWaitingForResponse) {
                    isWaitingForResponse = false;
                    isProcessingQuery = false;
                    if (window.processingTimeout) clearTimeout(window.processingTimeout);
                }

                if (data.type === 'text_start') {
                    addMessage(data.bot_text, 'assistant');
                    if (data.user_text) addMessage(data.user_text, 'user');
                    statusDiv.textContent = "ü§ñ Speaking...";
                    if (!isManualStop) startInterruptionDetection();
                }
                else if (data.type === 'audio_chunk') {
                    playAudioChunk(data.audio);
                }
                else if (data.audio && !data.type) {
                    addMessage(data.bot_text, 'assistant');
                    playAudioChunk(data.audio);
                }
                else if (data.type === 'error') {
                    statusDiv.textContent = "Error: " + data.message;
                }
            };

            // Ensures UI resets on close/error
            ws.onerror = () => handleConnectionLost("Socket Error");
            ws.onclose = () => handleConnectionLost("Socket Closed");
        }

        // --- BUTTONS ---
        micBtn.onclick = () => {
            isManualStop = false;
            if (isBotSpeaking) {
                handleInterruption();
                return;
            }
            // Connect logic
            if (!ws || ws.readyState !== WebSocket.OPEN) {
                initWebSocket();
            } else {
                startRecording();
            }
        };

        stopBtn.onclick = () => {
            // Send stop to server just in case
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ stop: true }));
            }
            // Call the centralized handler
            handleConnectionLost("Manual Stop Button");
        };

    </script>
</body>

</html>