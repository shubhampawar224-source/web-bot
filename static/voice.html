<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Agent (Smart Transcribe)</title>
    <style>
        body {
            font-family: 'Segoe UI', sans-serif;
            background-color: #f0f2f5;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
        }

        .main-container {
            width: 100%;
            max-width: 450px;
            height: 90vh;
            background: white;
            border-radius: 20px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .header {
            background: #007bff;
            color: white;
            padding: 15px;
            text-align: center;
            font-weight: 600;
        }

        .chat-box {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            background: #fff;
            display: flex;
            flex-direction: column;
            gap: 15px;
            scroll-behavior: smooth;
        }

        .message {
            max-width: 80%;
            padding: 10px 15px;
            border-radius: 15px;
            font-size: 0.95rem;
            line-height: 1.4;
            animation: fadeIn 0.3s ease;
            word-wrap: break-word;
        }

        .message.user {
            align-self: flex-end;
            background-color: #007bff;
            color: white;
            border-bottom-right-radius: 2px;
            text-align: right;
        }

        .message.assistant {
            align-self: flex-start;
            background-color: #e4e6eb;
            color: #050505;
            border-bottom-left-radius: 2px;
            text-align: left;
        }

        .controls {
            padding: 30px;
            background: #f8f9fa;
            display: flex;
            flex-direction: column;
            align-items: center;
            border-top: 1px solid #ddd;
            gap: 15px;
        }

        .status-text {
            font-size: 14px;
            font-family: 'Roboto', sans-serif;
            font-weight: 500;
            color: #333;
            letter-spacing: 0.5px;
            height: 20px;
        }

        .buttons-row {
            display: flex;
            gap: 40px;
            align-items: center;
            position: relative;
        }

        .btn {
            width: 70px;
            height: 70px;
            border-radius: 50%;
            border: none;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            transition: all 0.3s ease;
            position: relative;
            z-index: 2;
        }

        .btn svg {
            width: 30px;
            height: 30px;
            fill: white;
        }

        .btn:active {
            transform: scale(0.90);
        }

        #connectBtn {
            background-color: #28a745;
        }

        #connectBtn.active {
            background-color: #dc3545;
        }

        #connectBtn.speaking::before,
        #connectBtn.speaking::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 100%;
            height: 100%;
            border-radius: 50%;
            border: 2px solid #28a745;
            opacity: 0;
            z-index: -1;
        }

        #connectBtn.active.speaking::before,
        #connectBtn.active.speaking::after {
            border-color: #dc3545;
        }

        #connectBtn.speaking::before {
            animation: ripple 1.5s infinite;
        }

        #connectBtn.speaking::after {
            animation: ripple 1.5s infinite 0.4s;
        }

        #muteBtn {
            background-color: #6c757d;
            opacity: 0.5;
            pointer-events: none;
        }

        #muteBtn.active {
            opacity: 1;
            pointer-events: all;
            background-color: #007bff;
        }

        #muteBtn.muted {
            background-color: #ffc107;
        }

        #muteBtn.muted svg {
            fill: #333;
        }

        #connectBtn.ai-talking {
            box-shadow: 0 0 20px 5px rgba(0, 123, 255, 0.6);
            animation: breathe 1.5s infinite ease-in-out;
        }

        @keyframes ripple {
            0% {
                width: 100%;
                height: 100%;
                opacity: 0.8;
                border-width: 6px;
            }

            100% {
                width: 220%;
                height: 220%;
                opacity: 0;
                border-width: 0px;
            }
        }

        @keyframes breathe {
            0% {
                transform: scale(1);
                box-shadow: 0 0 20px 5px rgba(0, 123, 255, 0.6);
            }

            50% {
                transform: scale(1.1);
                box-shadow: 0 0 30px 10px rgba(0, 123, 255, 0.8);
            }

            100% {
                transform: scale(1);
                box-shadow: 0 0 20px 5px rgba(0, 123, 255, 0.6);
            }
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
    </style>
</head>

<body>
    <div class="main-container">
        <div class="header">üéôÔ∏è AI Voice Agent</div>
        <div class="chat-box" id="chatBox"></div>

        <div class="controls">
            <div class="status-text" id="statusText">Ready</div>

            <div class="buttons-row">
                <button id="muteBtn" class="btn" title="Pause Mic">
                    <svg id="iconUnmuted" viewBox="0 0 24 24">
                        <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z" />
                        <path
                            d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z" />
                    </svg>
                    <svg id="iconMuted" viewBox="0 0 24 24" style="display:none;">
                        <path
                            d="M19 11h-1.7c0 .74-.16 1.43-.43 2.05l1.23 1.23c.56-.98.9-2.09.9-3.28zm-4.02.17c0-.06.02-.11.02-.17V5c0-1.66-1.34-3-3-3S9 3.34 9 5v.18l5.98 5.99zM4.27 3L3 4.27l6.01 6.01V11c0 1.66 1.33 3 2.99 3 .22 0 .44-.03.65-.08l2.97 2.97c-.85.45-1.79.7-2.8.75v3.24h-2v-3.24c-3.28-.48-6.75-1.91-6.75-6.65h2c0 2.76 2.24 5 5 5 .37 0 .72-.06 1.06-.15l4.63 4.63L18.73 20 4.27 3z" />
                    </svg>
                </button>

                <button id="connectBtn" class="btn" title="Start/Stop Call">
                    <svg viewBox="0 0 24 24">
                        <path
                            d="M13 3h-2v10h2V3zm4.83 2.17l-1.42 1.42C17.99 7.86 19 9.81 19 12c0 3.87-3.13 7-7 7s-7-3.13-7-7c0-2.19 1.01-4.14 2.58-5.42L6.17 5.17C4.23 6.82 3 9.26 3 12c0 4.97 4.03 9 9 9s9-4.03 9-9c0-2.74-1.23-5.18-3.17-6.83z" />
                    </svg>
                </button>
            </div>
        </div>
    </div>
    <script>
        const chatBox = document.getElementById("chatBox");
        const statusText = document.getElementById("statusText");
        statusText.classList.add('status-text');
        const connectBtn = document.getElementById("connectBtn");
        const muteBtn = document.getElementById("muteBtn");
        const iconUnmuted = document.getElementById("iconUnmuted");
        const iconMuted = document.getElementById("iconMuted");

        let ws, audioCtx, playbackCtx, micWorklet, source, stream;
        let isRecording = false;
        let isMuted = false;

        let activeSources = [];
        let nextStartTime = 0;
        let isAiSpeaking = false;

        // Variables for Speech Hold (To fix Transcript)
        let lastSpeechTime = 0;
        const SPEECH_HOLD_TIME_MS = 400; // 400ms tak wait karega aawaz band hone ke baad
        const NOISE_GATE_THRESHOLD = 0.01; // Slightly more sensitive for better capture
        const MIC_SAMPLE_RATE = 24000;

        connectBtn.onclick = async () => {
            if (!isRecording) await startConnection();
            else stopConnection();
        };

        muteBtn.onclick = () => {
            if (!isRecording) return;
            isMuted = !isMuted;
            if (isMuted) {
                muteBtn.classList.add("muted");
                iconUnmuted.style.display = "none";
                iconMuted.style.display = "block";
                statusText.textContent = "Mic Muted";
                connectBtn.classList.remove("speaking");
            } else {
                muteBtn.classList.remove("muted");
                iconUnmuted.style.display = "block";
                iconMuted.style.display = "none";
                statusText.textContent = "Listening...";
            }
        };

        async function startConnection() {
            try {
                statusText.textContent = "Connecting...";
                connectBtn.classList.add("active");
                muteBtn.classList.add("active");
                isMuted = false;

                playbackCtx = new (window.AudioContext || window.webkitAudioContext)();
                nextStartTime = 0;

                audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: MIC_SAMPLE_RATE });
                if (audioCtx.state === 'suspended') await audioCtx.resume();

                const protocol = window.location.protocol === "https:" ? "wss:" : "ws:";
                const wsUrl = `${protocol}//${window.location.host}/ws/voice`;
                ws = new WebSocket(wsUrl);

                ws.onopen = async () => {
                    isRecording = true;
                    await startMicrophone();
                    statusText.textContent = "Connected. Speak now.";
                };

                ws.onmessage = async (event) => {
                    if (!isRecording) return;
                    const data = JSON.parse(event.data);

                    if (data.type === "transcript") addMessage(data.text, data.role);
                    if (data.type === "log") statusText.textContent = data.message;

                    if (data.type === "audio_chunk") {
                        statusText.textContent = "Speaking...";
                        isAiSpeaking = true;
                        connectBtn.classList.add("ai-talking");
                        handleAudioChunk(data.audio);
                    }
                };

                ws.onclose = () => { stopConnection(); statusText.textContent = "Disconnected"; };
                ws.onerror = (err) => { console.error("WS Error", err); statusText.textContent = "Connection Error"; }
            } catch (err) {
                console.error("Error:", err); statusText.textContent = "Error: " + err.message;
            }
        }

        function handleAudioChunk(base64Audio) {
            if (!playbackCtx || playbackCtx.state === 'closed') return;
            const binaryString = window.atob(base64Audio);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) bytes[i] = binaryString.charCodeAt(i);
            const float32Data = new Float32Array(len / 2);
            const dataView = new DataView(bytes.buffer);
            for (let i = 0; i < float32Data.length; i++) float32Data[i] = dataView.getInt16(i * 2, true) / 32768.0;

            const audioBuffer = playbackCtx.createBuffer(1, float32Data.length, 24000);
            audioBuffer.getChannelData(0).set(float32Data);
            const source = playbackCtx.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(playbackCtx.destination);

            const currentTime = playbackCtx.currentTime;
            if (nextStartTime < currentTime) nextStartTime = currentTime + 0.1;
            source.start(nextStartTime);
            nextStartTime += audioBuffer.duration;
            activeSources.push(source);

            source.onended = () => {
                activeSources = activeSources.filter(s => s !== source);
                if (activeSources.length === 0) {
                    isAiSpeaking = false;
                    connectBtn.classList.remove("ai-talking");
                    if (isRecording && !isMuted) statusText.textContent = "Listening...";
                }
            };
        }

        async function startMicrophone() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: MIC_SAMPLE_RATE,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: false
                    }
                });

                source = audioCtx.createMediaStreamSource(stream);
                const micCode = `
                class PCMProcessor extends AudioWorkletProcessor {
                    process(inputs, outputs) {
                        const input = inputs[0];
                        if (input.length > 0) this.port.postMessage(input[0]);
                        return true;
                    }
                }
                registerProcessor('pcm-processor', PCMProcessor);
            `;
                const blob = new Blob([micCode], { type: "text/javascript" });
                await audioCtx.audioWorklet.addModule(URL.createObjectURL(blob));
                micWorklet = new AudioWorkletNode(audioCtx, 'pcm-processor');

                let bufferAccumulator = [];

                micWorklet.port.onmessage = (e) => {
                    if (!isRecording || ws.readyState !== WebSocket.OPEN) return;

                    const float32Chunk = e.data;

                    if (isMuted) return;

                    // RMS Calculation
                    let sum = 0;
                    for (let i = 0; i < float32Chunk.length; i++) {
                        sum += float32Chunk[i] * float32Chunk[i];
                    }
                    const rms = Math.sqrt(sum / float32Chunk.length);

                    // ‚≠ê SMART SPEECH HOLD LOGIC ‚≠ê
                    // Agar aawaz threshold se upar hai, toh timer reset karo
                    if (rms > NOISE_GATE_THRESHOLD) {
                        lastSpeechTime = Date.now();
                        connectBtn.classList.add("speaking");

                        // Interrupt AI if speaking
                        if (isAiSpeaking) {
                            stopAudioPlayback();
                            isAiSpeaking = false;
                            connectBtn.classList.remove("ai-talking");
                        }
                    }

                    // Check: Kya abhi bhi "Hold Time" ke andar hain?
                    // (Matlab user chup hua hai lekin 400ms nahi hue hain)
                    const timeSinceLastSpeech = Date.now() - lastSpeechTime;

                    if (timeSinceLastSpeech < SPEECH_HOLD_TIME_MS) {
                        // SEND AUDIO (Speaking phase or Holding phase)
                        // Do nothing here, let the buffer process below
                    } else {
                        // SEND SILENCE (Noise Gate Active)
                        // Aawaz zero kar do taaki background noise na jaye
                        for (let i = 0; i < float32Chunk.length; i++) {
                            float32Chunk[i] = 0;
                        }
                        connectBtn.classList.remove("speaking");
                    }

                    bufferAccumulator.push(...float32Chunk);
                    if (bufferAccumulator.length >= 4096) {
                        const chunkToSend = new Float32Array(bufferAccumulator);
                        bufferAccumulator = [];
                        const pcmData = floatTo16BitPCM(chunkToSend);
                        const base64Audio = arrayBufferToBase64(pcmData);
                        ws.send(JSON.stringify({ audio: base64Audio }));
                    }
                };
                source.connect(micWorklet);
                micWorklet.connect(audioCtx.destination);
            } catch (error) { console.error("Mic Error:", error); }
        }

        function stopConnection() {
            isRecording = false;
            connectBtn.classList.remove("active");
            connectBtn.classList.remove("speaking");
            connectBtn.classList.remove("ai-talking");
            muteBtn.classList.remove("active");
            muteBtn.classList.remove("muted");

            iconUnmuted.style.display = "block";
            iconMuted.style.display = "none";
            statusText.textContent = "Ready to Connect";

            if (ws) { ws.close(); ws = null; }
            stopAudioPlayback();
            if (playbackCtx) { playbackCtx.close(); playbackCtx = null; }
            if (audioCtx) { audioCtx.close(); audioCtx = null; }
            if (stream) { stream.getTracks().forEach(t => t.stop()); stream = null; }
        }

        function stopAudioPlayback() {
            activeSources.forEach(s => { try { s.stop(); } catch (e) { } });
            activeSources = [];
            if (playbackCtx) nextStartTime = playbackCtx.currentTime;
        }

        function addMessage(text, role) {
            if (!text) return;
            const div = document.createElement("div");
            div.className = `message ${role}`; div.textContent = text;
            chatBox.appendChild(div);
            chatBox.scrollTo({ top: chatBox.scrollHeight, behavior: 'smooth' });
        }

        function floatTo16BitPCM(input) {
            const output = new Int16Array(input.length);
            for (let i = 0; i < input.length; i++) {
                const s = Math.max(-1, Math.min(1, input[i]));
                output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return output.buffer;
        }

        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) { binary += String.fromCharCode(bytes[i]); }
            return window.btoa(binary);
        }
    </script>

</body>

</html>