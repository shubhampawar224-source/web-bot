<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant (Fast VAD)</title>
    <style>
        /* --- CSS STYLES --- */
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f0f2f5;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
        }

        .main-container {
            width: 100%;
            max-width: 450px;
            height: 80vh;
            background: white;
            border-radius: 20px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .header {
            background: #007bff;
            color: white;
            padding: 15px;
            text-align: center;
            font-weight: 600;
            font-size: 1.1rem;
        }

        .chat-box {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            background: #fff;
            display: flex;
            flex-direction: column;
            gap: 15px;
            scroll-behavior: smooth;
        }

        .message {
            max-width: 80%;
            padding: 10px 15px;
            border-radius: 15px;
            font-size: 0.95rem;
            line-height: 1.4;
            animation: fadeIn 0.3s ease;
            word-wrap: break-word;
        }

        .message.user {
            align-self: flex-end;
            background-color: #007bff;
            color: white;
            border-bottom-right-radius: 2px;
            text-align: right;
        }

        .message.assistant {
            align-self: flex-start;
            background-color: #e4e6eb;
            color: #050505;
            border-bottom-left-radius: 2px;
            text-align: left;
        }

        .controls {
            padding: 20px;
            background: #f8f9fa;
            display: flex;
            flex-direction: column;
            align-items: center;
            border-top: 1px solid #ddd;
        }

        .status-text {
            margin-bottom: 15px;
            font-size: 0.9rem;
            color: #555;
            height: 20px;
        }

        .mic-button {
            width: 70px;
            height: 70px;
            border-radius: 50%;
            background-color: #007bff;
            border: none;
            cursor: pointer;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: 0 4px 15px rgba(0, 123, 255, 0.3);
            transition: all 0.2s ease;
        }

        .mic-button svg {
            width: 30px;
            height: 30px;
            fill: white;
        }

        .mic-button.recording {
            background-color: #dc3545;
            box-shadow: 0 0 0 5px rgba(220, 53, 69, 0.2);
        }

        /* ‚≠ê Visual Feedback for Sending Audio */
        .mic-button.sending {
            background-color: #28a745 !important;
            /* Green blink */
            transform: scale(0.95);
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
    </style>
</head>

<body>

    <div class="main-container">
        <div class="header">üéôÔ∏è AI Voice Agent</div>

        <div class="chat-box" id="chatBox"></div>

        <div class="controls">
            <div class="status-text" id="statusText">Ready</div>
            <button class="mic-button" id="micBtn">
                <svg viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z" />
                    <path
                        d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z" />
                </svg>
            </button>
        </div>
    </div>

    <script>
        const chatBox = document.getElementById("chatBox");
        const statusText = document.getElementById("statusText");
        const micBtn = document.getElementById("micBtn");

        let ws;
        let audioCtx;
        let workletNode;
        let source;
        let stream;
        let isRecording = false;

        const SAMPLE_RATE = 24000;

        micBtn.onclick = async () => {
            if (!isRecording) {
                await startConnection();
            } else {
                stopConnection();
            }
        };

        async function startConnection() {
            try {
                statusText.textContent = "Connecting...";

                // Initialize Audio Context immediately (User Gesture)
                if (!audioCtx) {
                    audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: SAMPLE_RATE });
                }
                if (audioCtx.state === 'suspended') {
                    await audioCtx.resume();
                }

                ws = new WebSocket("ws://" + location.host + "/ws/voice");

                ws.onopen = async () => {
                    statusText.textContent = "Connected. Starting Mic...";
                    micBtn.classList.add("recording");
                    isRecording = true;
                    await startMicrophone();
                    statusText.textContent = "Listening...";
                };

                ws.onmessage = async (event) => {
                    const data = JSON.parse(event.data);

                    if (data.type === "transcript") {
                        addMessage(data.text, data.role);
                    }

                    if (data.type === "log") {
                        statusText.textContent = data.message;
                    }

                    if (data.type === "audio_chunk") {
                        statusText.textContent = "Speaking...";
                        await playAudioChunk(data.audio);
                    }
                };

                ws.onclose = () => {
                    stopConnection();
                    statusText.textContent = "Disconnected";
                };

                ws.onerror = (err) => {
                    console.error("WS Error", err);
                    statusText.textContent = "Connection Error";
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.textContent = "Error: " + err.message;
            }
        }

        async function startMicrophone() {
            stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    sampleRate: SAMPLE_RATE,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true // Helps if volume is low
                }
            });

            source = audioCtx.createMediaStreamSource(stream);

            const processorCode = `
                class PCMProcessor extends AudioWorkletProcessor {
                    process(inputs, outputs, parameters) {
                        const input = inputs[0];
                        if (input.length > 0) {
                            const float32Data = input[0];
                            this.port.postMessage(float32Data);
                        }
                        return true;
                    }
                }
                registerProcessor('pcm-processor', PCMProcessor);
            `;

            const blob = new Blob([processorCode], { type: "text/javascript" });
            const url = URL.createObjectURL(blob);

            try {
                await audioCtx.audioWorklet.addModule(url);
            } catch (e) {
                // Ignore if already added
            }

            workletNode = new AudioWorkletNode(audioCtx, 'pcm-processor');

            let bufferAccumulator = [];

            workletNode.port.onmessage = (e) => {
                if (!isRecording || ws.readyState !== WebSocket.OPEN) return;

                const float32Chunk = e.data;
                bufferAccumulator.push(...float32Chunk);

                // ‚≠ê FIXED: Reduced buffer size from 4096 to 1024 (Faster sending)
                if (bufferAccumulator.length >= 1024) {
                    const chunkToSend = new Float32Array(bufferAccumulator);
                    bufferAccumulator = [];

                    const pcmData = floatTo16BitPCM(chunkToSend);
                    const base64Audio = arrayBufferToBase64(pcmData);
                    ws.send(JSON.stringify({ audio: base64Audio }));

                    // Visual Feedback (Blink Green)
                    requestAnimationFrame(() => {
                        micBtn.classList.add("sending");
                        setTimeout(() => micBtn.classList.remove("sending"), 100);
                    });
                }
            };

            source.connect(workletNode);
            workletNode.connect(audioCtx.destination);
        }

        function stopConnection() {
            isRecording = false;
            micBtn.classList.remove("recording");
            statusText.textContent = "Ready";

            if (workletNode) { workletNode.disconnect(); workletNode = null; }
            if (source) { source.disconnect(); source = null; }
            if (stream) { stream.getTracks().forEach(track => track.stop()); stream = null; }
            if (ws) { ws.close(); ws = null; }
            // Note: Don't close audioCtx, just reuse it
        }

        function addMessage(text, role) {
            if (!text) return;
            const div = document.createElement("div");
            div.className = `message ${role}`;
            div.textContent = text;
            chatBox.appendChild(div);
            chatBox.scrollTo({ top: chatBox.scrollHeight, behavior: 'smooth' });
        }

        // --- UTILS ---
        function floatTo16BitPCM(input) {
            const output = new Int16Array(input.length);
            for (let i = 0; i < input.length; i++) {
                const s = Math.max(-1, Math.min(1, input[i]));
                output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return output.buffer;
        }

        function arrayBufferToBase64(buffer) {
            let binary = '';
            const bytes = new Uint8Array(buffer);
            const len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return window.btoa(binary);
        }

        // --- AUDIO PLAYER ---
        // Using separate context for playback to avoid mic feedback loops issues
        let playbackCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        let nextStartTime = 0;

        async function playAudioChunk(base64Audio) {
            try {
                if (playbackCtx.state === 'suspended') await playbackCtx.resume();

                const binaryString = window.atob(base64Audio);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) { bytes[i] = binaryString.charCodeAt(i); }

                const wavBytes = addWavHeader(bytes, 24000, 1);
                const audioBuffer = await playbackCtx.decodeAudioData(wavBytes.buffer);

                const source = playbackCtx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(playbackCtx.destination);

                const now = playbackCtx.currentTime;
                if (nextStartTime < now) nextStartTime = now;

                source.start(nextStartTime);
                nextStartTime += audioBuffer.duration;

                source.onended = () => {
                    if (playbackCtx.currentTime >= nextStartTime && isRecording) {
                        statusText.textContent = "Listening...";
                    }
                };
            } catch (e) {
                console.error("Playback error", e);
            }
        }

        function addWavHeader(samples, sampleRate, numChannels) {
            const buffer = new ArrayBuffer(44 + samples.length);
            const view = new DataView(buffer);
            const writeString = (view, offset, string) => {
                for (let i = 0; i < string.length; i++) view.setUint8(offset + i, string.charCodeAt(i));
            };
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + samples.length, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * numChannels * 2, true);
            view.setUint16(32, numChannels * 2, true);
            view.setUint16(34, 16, true);
            writeString(view, 36, 'data');
            view.setUint32(40, samples.length, true);
            const dataView = new Uint8Array(buffer, 44);
            dataView.set(samples);
            return new Uint8Array(buffer);
        }
    </script>
</body>

</html>